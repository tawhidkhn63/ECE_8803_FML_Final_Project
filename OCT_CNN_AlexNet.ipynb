{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "LABELS_Severity = {35: 0, 43: 0, 47: 1, 53: 1, 61: 2, 65: 2, 71: 2, 85: 2}\n",
    "\n",
    "mean = (.1706)\n",
    "std = (.2112)\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "#Check if GPU is being used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "#Define the dataloader class\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, subset='train', transform=None):\n",
    "        if subset == 'train':\n",
    "            self.annot = pd.read_csv('df_prime_train.csv')\n",
    "        elif subset == 'test':\n",
    "            self.annot = pd.read_csv('df_prime_test.csv')\n",
    "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)]\n",
    "        self.root = os.path.expanduser('/storage/home/hpaceice1/shared-classes/materials/ece8803fml/')\n",
    "        self.transform = transform\n",
    "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
    "        self.path_list = self.annot['File_Path'].values\n",
    "        self._labels = self.annot['Severity_Label'].values\n",
    "        assert len(self.path_list) == len(self._labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = Image.open(self.root+self.path_list[index]).convert(\"L\"), self._labels[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define AlexNet Model\n",
    "def AlexNetClassifier():\n",
    "    \n",
    "    model = torchvision.models.alexnet()\n",
    "    model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "        \n",
    "    # Replace the last layer\n",
    "    num_classes = 3\n",
    "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    \n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model and the training loop\n",
    "Alex_Model = AlexNetClassifier()\n",
    "\n",
    "# Define hyperparameters: Batch Size, Learning Rate, Number of Epochs\n",
    "batch_size = 100\n",
    "lr = 0.0001\n",
    "num_epochs = 20\n",
    "\n",
    "# Define loss function and optimizer\n",
    "Loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Alex_Model.parameters(), lr=lr)\n",
    "epoch = 0\n",
    "\n",
    "def train_AlexNet(train_loader):\n",
    "    Alex_Model.train()\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the CNN on the images in the training set\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to('cuda') \n",
    "            labels = labels.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "            outputs = Alex_Model(images)\n",
    "            loss = Loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "         \n",
    "        print('Epoch: {} | Train loss: {:0.4f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created training and testing sets\n",
      "Successfully created the Dataloaders\n",
      "Epoch: 0 | Train loss: 0.7068\n",
      "Epoch: 1 | Train loss: 0.5133\n",
      "Epoch: 2 | Train loss: 0.6089\n",
      "Epoch: 3 | Train loss: 0.4136\n",
      "Epoch: 4 | Train loss: 0.4690\n",
      "Epoch: 5 | Train loss: 0.4128\n",
      "Epoch: 6 | Train loss: 0.3927\n",
      "Epoch: 7 | Train loss: 0.3284\n",
      "Epoch: 8 | Train loss: 0.2819\n",
      "Epoch: 9 | Train loss: 0.2350\n",
      "Epoch: 10 | Train loss: 0.3248\n",
      "Epoch: 11 | Train loss: 0.1207\n",
      "Epoch: 12 | Train loss: 0.1994\n",
      "Epoch: 13 | Train loss: 0.2309\n",
      "Epoch: 14 | Train loss: 0.1083\n",
      "Epoch: 15 | Train loss: 0.1628\n",
      "Epoch: 16 | Train loss: 0.1460\n",
      "Epoch: 17 | Train loss: 0.1437\n",
      "Epoch: 18 | Train loss: 0.1749\n",
      "Epoch: 19 | Train loss: 0.1702\n"
     ]
    }
   ],
   "source": [
    "#Create training & testing sets\n",
    "trainset = OCTDataset( 'train', transform=transform)\n",
    "testset = OCTDataset( 'test', transform=transform)\n",
    "print('Successfully created training and testing sets')\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "print('Successfully created the Dataloaders')\n",
    "\n",
    "#Train the ALexNet model\n",
    "train_AlexNet(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1005\n",
      "Testing Loss: 4.1615\n"
     ]
    }
   ],
   "source": [
    "#Training & Testing Set performances\n",
    "def evaluate_loss(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            outputs = model(images)\n",
    "            loss = Loss_fn(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            num_batches += 1\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# Compute training and testing loss\n",
    "train_loss = evaluate_loss(Alex_Model, train_loader)\n",
    "test_loss = evaluate_loss(Alex_Model, test_loader)\n",
    "\n",
    "print('Training Loss: {:.4f}'.format(train_loss))\n",
    "print('Testing Loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/storage/home/hpaceice1/shussain81/.conda/envs/ece8803/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Balanced Accuracy Score:0.3353\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "#Compute different performance metrics\n",
    "Alex_Model.eval()\n",
    "with torch.no_grad():\n",
    "    test_acc = 0.0\n",
    "    test_f1 = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = Alex_Model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(predicted.tolist())\n",
    "        test_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "            \n",
    "    # Print training progress\n",
    "    print(f\"Test Balanced Accuracy Score:{test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 809 1275  464]\n",
      " [ 949 2115  856]\n",
      " [ 733  560  226]]\n",
      "Accuracy: 0.3944\n",
      "Balanced accuracy: 0.3353\n",
      "Precision: 0.3355\n",
      "Recall: 0.3353\n",
      "F1-score: 0.3354\n",
      "True positive rate (recall): 0.6903\n",
      "False positive rate (1 - specificity): 0.6118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# y_test and y_pred are defined as in the previous example\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Compute accuracy and balanced accuracy scores\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Compute precision, recall, and f1-score\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Compute true positive rate (recall) and false positive rate (1 - specificity)\n",
    "if cm.shape == (2, 2):  # binary classification\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "else:  # multiclass classification\n",
    "    tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy: {:.4f}\".format(acc))\n",
    "print(\"Balanced accuracy: {:.4f}\".format(bacc))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1-score: {:.4f}\".format(f1))\n",
    "print(\"True positive rate (recall): {:.4f}\".format(tpr))\n",
    "print(\"False positive rate (1 - specificity): {:.4f}\".format(fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ece8803]",
   "language": "python",
   "name": "conda-env-.conda-ece8803-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
