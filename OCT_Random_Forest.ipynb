{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "LABELS_Severity = {35: 0, 43: 0, 47: 1, 53: 1, 61: 2, 65: 2, 71: 2, 85: 2}\n",
    "\n",
    "mean = (.1706)\n",
    "std = (.2112)\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "#Check if GPU is being used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "#Define the dataloader class\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, subset='train', transform=None):\n",
    "        if subset == 'train':\n",
    "            self.annot = pd.read_csv('df_prime_train.csv')\n",
    "        elif subset == 'test':\n",
    "            self.annot = pd.read_csv('df_prime_test.csv')\n",
    "        \n",
    "        self.annot = self.annot.sample(frac=0.5, random_state=42)\n",
    "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)]\n",
    "        self.root = os.path.expanduser('/storage/home/hpaceice1/shared-classes/materials/ece8803fml/')\n",
    "        self.transform = transform\n",
    "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
    "        self.path_list = self.annot['File_Path'].values\n",
    "        self._labels = self.annot['Severity_Label'].values\n",
    "        assert len(self.path_list) == len(self._labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = Image.open(self.root+self.path_list[index]).convert(\"L\"), self._labels[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the dataset\n",
    "dataset = OCTDataset(subset='train', transform=transform)\n",
    "\n",
    "# Define the dataloader\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Prepare the data for training\n",
    "X, y = [], []\n",
    "for batch_idx, (data, target) in enumerate(dataloader):\n",
    "    X_batch = data.detach().cpu().numpy()\n",
    "    y_batch = target.detach().cpu().numpy()\n",
    "    X.append(X_batch.reshape(X_batch.shape[0], -1))\n",
    "    y.append(y_batch)\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.concatenate(y, axis=0)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the classifier and fit to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 576  199    1]\n",
      " [ 147 1010   34]\n",
      " [  25  112  322]]\n",
      "Accuracy: 0.7865\n",
      "Balanced accuracy: 0.7639\n",
      "Precision: 0.8122\n",
      "Recall: 0.7639\n",
      "F1-score: 0.7831\n",
      "True positive rate (recall): 0.8729\n",
      "False positive rate (1 - specificity): 0.2568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# y_test and y_pred are defined as in the previous example\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Compute accuracy and balanced accuracy scores\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Compute precision, recall, and f1-score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Compute true positive rate (recall) and false positive rate (1 - specificity)\n",
    "if cm.shape == (2, 2):  # binary classification\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "else:  # multiclass classification\n",
    "    tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy: {:.4f}\".format(acc))\n",
    "print(\"Balanced accuracy: {:.4f}\".format(bacc))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1-score: {:.4f}\".format(f1))\n",
    "print(\"True positive rate (recall): {:.4f}\".format(tpr))\n",
    "print(\"False positive rate (1 - specificity): {:.4f}\".format(fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "dataset = OCTDataset(subset='train', transform=transform)\n",
    "\n",
    "#Define performance metrics as lists\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "acc = []\n",
    "bacc = []\n",
    "tpr = []\n",
    "fpr = []\n",
    "\n",
    "# Define batch size and dataloader\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Prepare the data for training\n",
    "X, y = [], []\n",
    "for batch_idx, (data, target) in enumerate(dataloader):\n",
    "    X_batch = data.detach().cpu().numpy()\n",
    "    y_batch = target.detach().cpu().numpy()\n",
    "    X.append(X_batch.reshape(X_batch.shape[0], -1))\n",
    "    y.append(y_batch)\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.concatenate(y, axis=0)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Define \n",
    "n_estimators = list(range(10,205,25))\n",
    "\n",
    "for i in n_estimators:\n",
    "    # Define the classifier and fit to the training data\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=None, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Compute accuracy and balanced accuracy scores\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    bacc.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Compute precision, recall, and f1-score\n",
    "    precision.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "    # Compute true positive rate (recall) and false positive rate (1 - specificity)\n",
    "    if cm.shape == (2, 2):  # binary classification\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:  # multiclass classification\n",
    "        tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "    tpr.append(tp / (tp + fn))\n",
    "    fpr.append(fp / (fp + tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(n_estimators, acc, linestyle = '-', color='blue', label='Accuracy')\n",
    "plt.plot(n_estimators, bacc, linestyle = '-', color='red', label='Balanced Accuracy')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ece8803]",
   "language": "python",
   "name": "conda-env-.conda-ece8803-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
